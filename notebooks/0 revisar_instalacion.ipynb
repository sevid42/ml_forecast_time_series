{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e912dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "373c321c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas: 2.3.3\n",
      "NumPy: 2.3.4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a5a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b128eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def analizar_dataframe(df):\n",
    "    \"\"\"\n",
    "    Análisis eficiente de DataFrame usando operaciones vectorizadas.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame a analizar\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame con el análisis de cada columna\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pre-calcular información común para todas las columnas\n",
    "    total_filas = len(df)\n",
    "    \n",
    "    # Lista para almacenar resultados\n",
    "    resultados = []\n",
    "    \n",
    "    for columna in df.columns:\n",
    "        col_data = df[columna]\n",
    "        \n",
    "        # Tipo de dato (más eficiente con select_dtypes)\n",
    "        es_numerica = pd.api.types.is_numeric_dtype(col_data)\n",
    "        tipo = 'Numérica' if es_numerica else 'Alfanumérica'\n",
    "        \n",
    "        # Máscara de nulos (calcular una sola vez)\n",
    "        mask_nulos = col_data.isna()\n",
    "        cantidad_nulos = mask_nulos.sum()\n",
    "        \n",
    "        # Valores distintos (incluidos null) - muy eficiente\n",
    "        valores_distintos = col_data.nunique(dropna=False)\n",
    "        \n",
    "        # Inicializar contadores\n",
    "        cantidad_blancos = 0\n",
    "        cantidad_ceros = 0\n",
    "        cantidad_negativos = 0\n",
    "        \n",
    "        if es_numerica:\n",
    "            # Operaciones vectorizadas para numéricos (muy rápido)\n",
    "            col_no_nulos = col_data.dropna()\n",
    "            if len(col_no_nulos) > 0:\n",
    "                cantidad_ceros = (col_no_nulos == 0).sum()\n",
    "                cantidad_negativos = (col_no_nulos < 0).sum()\n",
    "        else:\n",
    "            # Para alfanuméricos, usar operaciones de string vectorizadas\n",
    "            # Más eficiente que apply\n",
    "            if col_data.dtype == 'object':\n",
    "                # Filtrar solo strings y contar blancos en una operación\n",
    "                mask_strings = col_data.apply(lambda x: isinstance(x, str))\n",
    "                if mask_strings.any():\n",
    "                    cantidad_blancos = col_data[mask_strings].str.strip().eq('').sum()\n",
    "        \n",
    "        # 5 valores de ejemplo (optimizado)\n",
    "        valores_unicos = col_data.dropna().unique()\n",
    "        valores_ejemplo = valores_unicos[:5] if len(valores_unicos) > 0 else []\n",
    "        valores_ejemplo_str = ', '.join(map(str, valores_ejemplo))\n",
    "        \n",
    "        # Agregar resultados\n",
    "        resultados.append({\n",
    "            'Columna': columna,\n",
    "            'Tipo': tipo,\n",
    "            'Total Valores': total_filas,\n",
    "            'Nulos': int(cantidad_nulos),\n",
    "            'Valores Distintos': int(valores_distintos),\n",
    "            'Valores Blancos': int(cantidad_blancos),\n",
    "            'Valores Cero': int(cantidad_ceros),\n",
    "            'Valores Negativos': int(cantidad_negativos),\n",
    "            'Ejemplos': valores_ejemplo_str\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "\n",
    "def analizar_csv(ruta_archivo, separador=',', encoding='utf-8', nrows=None):\n",
    "    \"\"\"\n",
    "    Lee y analiza un archivo CSV de forma eficiente.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ruta_archivo : str\n",
    "        Ruta del archivo CSV\n",
    "    separador : str, default=','\n",
    "        Separador del CSV\n",
    "    encoding : str, default='utf-8'\n",
    "        Codificación del archivo\n",
    "    nrows : int, optional\n",
    "        Número de filas a leer (útil para archivos grandes)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (DataFrame original, DataFrame de análisis)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Leyendo archivo: {ruta_archivo}\")\n",
    "    \n",
    "    # Leer CSV con optimizaciones\n",
    "    df = pd.read_csv(\n",
    "        ruta_archivo, \n",
    "        sep=separador, \n",
    "        encoding=encoding,\n",
    "        nrows=nrows,\n",
    "        low_memory=False  # Más rápido para archivos grandes\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Archivo cargado: {df.shape[0]:,} filas, {df.shape[1]} columnas\\n\")\n",
    "    \n",
    "    print(\"Analizando columnas...\")\n",
    "    df_analisis = analizar_dataframe(df)\n",
    "    print(\"✓ Análisis completado\\n\")\n",
    "    \n",
    "    return df, df_analisis\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# VERSIÓN ULTRA OPTIMIZADA (para Big Data)\n",
    "# ============================================\n",
    "\n",
    "def analizar_csv_chunked(ruta_archivo, chunksize=10000, separador=',', encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    Analiza archivos CSV muy grandes por chunks (evita cargar todo en memoria).\n",
    "    Ideal para datasets de millones de filas.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ruta_archivo : str\n",
    "        Ruta del archivo CSV\n",
    "    chunksize : int, default=10000\n",
    "        Número de filas por chunk\n",
    "    separador : str, default=','\n",
    "        Separador del CSV\n",
    "    encoding : str, default='utf-8'\n",
    "        Codificación del archivo\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame con el análisis de cada columna\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Analizando archivo por chunks de {chunksize:,} filas...\")\n",
    "    \n",
    "    # Diccionarios para acumular estadísticas\n",
    "    stats = {}\n",
    "    total_rows = 0\n",
    "    \n",
    "    # Leer por chunks\n",
    "    for i, chunk in enumerate(pd.read_csv(ruta_archivo, sep=separador, \n",
    "                                          encoding=encoding, chunksize=chunksize)):\n",
    "        \n",
    "        total_rows += len(chunk)\n",
    "        \n",
    "        for columna in chunk.columns:\n",
    "            if columna not in stats:\n",
    "                # Inicializar estadísticas para nueva columna\n",
    "                es_numerica = pd.api.types.is_numeric_dtype(chunk[columna])\n",
    "                stats[columna] = {\n",
    "                    'tipo': 'Numérica' if es_numerica else 'Alfanumérica',\n",
    "                    'nulos': 0,\n",
    "                    'valores_unicos': set(),\n",
    "                    'blancos': 0,\n",
    "                    'ceros': 0,\n",
    "                    'negativos': 0,\n",
    "                    'ejemplos': []\n",
    "                }\n",
    "            \n",
    "            col_data = chunk[columna]\n",
    "            col_stats = stats[columna]\n",
    "            \n",
    "            # Acumular nulos\n",
    "            col_stats['nulos'] += col_data.isna().sum()\n",
    "            \n",
    "            # Acumular valores únicos (limitado para eficiencia)\n",
    "            if len(col_stats['valores_unicos']) < 10000:\n",
    "                col_stats['valores_unicos'].update(col_data.dropna().unique())\n",
    "            \n",
    "            # Ejemplos (solo del primer chunk)\n",
    "            if i == 0 and len(col_stats['ejemplos']) < 5:\n",
    "                ejemplos = col_data.dropna().unique()[:5].tolist()\n",
    "                col_stats['ejemplos'].extend(ejemplos)\n",
    "            \n",
    "            # Estadísticas específicas por tipo\n",
    "            if col_stats['tipo'] == 'Numérica':\n",
    "                col_no_nulos = col_data.dropna()\n",
    "                col_stats['ceros'] += (col_no_nulos == 0).sum()\n",
    "                col_stats['negativos'] += (col_no_nulos < 0).sum()\n",
    "            else:\n",
    "                if col_data.dtype == 'object':\n",
    "                    mask_strings = col_data.apply(lambda x: isinstance(x, str))\n",
    "                    if mask_strings.any():\n",
    "                        col_stats['blancos'] += col_data[mask_strings].str.strip().eq('').sum()\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"  Procesados {total_rows:,} filas...\")\n",
    "    \n",
    "    print(f\"✓ Análisis completado: {total_rows:,} filas totales\\n\")\n",
    "    \n",
    "    # Construir DataFrame de resultados\n",
    "    resultados = []\n",
    "    for columna, col_stats in stats.items():\n",
    "        resultados.append({\n",
    "            'Columna': columna,\n",
    "            'Tipo': col_stats['tipo'],\n",
    "            'Total Valores': total_rows,\n",
    "            'Nulos': int(col_stats['nulos']),\n",
    "            'Valores Distintos': len(col_stats['valores_unicos']),\n",
    "            'Valores Blancos': int(col_stats['blancos']),\n",
    "            'Valores Cero': int(col_stats['ceros']),\n",
    "            'Valores Negativos': int(col_stats['negativos']),\n",
    "            'Ejemplos': ', '.join(map(str, col_stats['ejemplos'][:5]))\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# EJEMPLO DE USO\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # ===== PARA ARCHIVOS NORMALES (< 1 GB) =====\n",
    "    ruta_csv = 'data/raw/tu_archivo.csv'\n",
    "    df_original, df_analisis = analizar_csv(ruta_csv)\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    print(\"ANÁLISIS DE COLUMNAS\")\n",
    "    print(\"=\" * 100)\n",
    "    print(df_analisis.to_string(index=False))\n",
    "    \n",
    "    # ===== PARA ARCHIVOS GRANDES (> 1 GB) =====\n",
    "    # df_analisis = analizar_csv_chunked(ruta_csv, chunksize=50000)\n",
    "    # print(df_analisis.to_string(index=False))\n",
    "    \n",
    "    # Guardar resultado\n",
    "    df_analisis.to_csv('reports/analisis_columnas.csv', index=False)\n",
    "    print(\"\\n✓ Análisis guardado en: reports/analisis_columnas.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_forecast_time_series",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
